{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b21851e",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db03b82-98d8-40dd-ae5f-96b4f256536e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:15.001364Z",
     "start_time": "2024-03-31T14:53:14.330180Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUTPUT_FOLDER = 'model/'\n",
    "\n",
    "seed = 88\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6de5829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:16.134611Z",
     "start_time": "2024-03-31T14:53:15.002338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file with specified column names\n",
    "df = pd.read_csv(\"dataset/steam_dataset_200000.csv\", index_col= 0)\n",
    "\n",
    "def reduce_sample(df_sample, frac, random_state):\n",
    "    df_sample = df_sample.sample(frac=frac, random_state=random_state)\n",
    "    df_sample = df_sample.reset_index(drop=True)\n",
    "    return df_sample\n",
    "frac_pop = 1\n",
    "df = reduce_sample(df, frac_pop, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6aa034",
   "metadata": {},
   "source": [
    "Columns in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477335fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:16.150221Z",
     "start_time": "2024-03-31T14:53:16.135649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the original dataset:\n",
      "\n",
      "Index(['app_id', 'app_name', 'review_text', 'review_score', 'review_votes'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in the original dataset:\\n\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2a23b",
   "metadata": {},
   "source": [
    "Example of a Row in dataset"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   app_id               app_name  \\\n0  322330  Don't Starve Together   \n1  218620               PAYDAY 2   \n2  372800                 RPG MO   \n3  453090              Parkitect   \n4  236390            War Thunder   \n\n                                         review_text  review_score  \\\n0                                Early Access Review             1   \n1  PAYDAY 2 is an action-packed, four-player co-o...             1   \n2                                Early Access Review             1   \n3                                Early Access Review             1   \n4  This is my first diccusion and hope it don't h...            -1   \n\n   review_votes  \n0             0  \n1             0  \n2             0  \n3             0  \n4             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>app_id</th>\n      <th>app_name</th>\n      <th>review_text</th>\n      <th>review_score</th>\n      <th>review_votes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>322330</td>\n      <td>Don't Starve Together</td>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>218620</td>\n      <td>PAYDAY 2</td>\n      <td>PAYDAY 2 is an action-packed, four-player co-o...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>372800</td>\n      <td>RPG MO</td>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>453090</td>\n      <td>Parkitect</td>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>236390</td>\n      <td>War Thunder</td>\n      <td>This is my first diccusion and hope it don't h...</td>\n      <td>-1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:16.165997Z",
     "start_time": "2024-03-31T14:53:16.151735Z"
    }
   },
   "id": "5553cabf15b246e3",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689c8807",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:16.181448Z",
     "start_time": "2024-03-31T14:53:16.167030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "review_score\n 1    100000\n-1    100000\nName: count, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d146b21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:16.212121Z",
     "start_time": "2024-03-31T14:53:16.182422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              app_id   review_score   review_votes\ncount  200000.000000  200000.000000  200000.000000\nmean   235172.063805       0.000000       0.183330\nstd    123389.931619       1.000003       0.386938\nmin        10.000000      -1.000000       0.000000\n25%    206420.000000      -1.000000       0.000000\n50%    244210.000000       0.000000       0.000000\n75%    311240.000000       1.000000       0.000000\nmax    562710.000000       1.000000       1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>app_id</th>\n      <th>review_score</th>\n      <th>review_votes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>200000.000000</td>\n      <td>200000.000000</td>\n      <td>200000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>235172.063805</td>\n      <td>0.000000</td>\n      <td>0.183330</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>123389.931619</td>\n      <td>1.000003</td>\n      <td>0.386938</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>10.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>206420.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>244210.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>311240.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>562710.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa9c1c4",
   "metadata": {},
   "source": [
    "Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c21871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:16.536542Z",
     "start_time": "2024-03-31T14:53:16.213052Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_dataset(df_to_clean, drop_columns):\n",
    "    df_to_clean = df_to_clean.dropna()\n",
    "    df_to_clean = df_to_clean.drop_duplicates()\n",
    "    df_to_clean = df_to_clean.drop(columns=drop_columns)\n",
    "    df_to_clean = df_to_clean.reset_index(drop=True)\n",
    "    df_to_clean.describe()\n",
    "    return df_to_clean\n",
    "\n",
    "df_cleaned = clean_dataset(df, [\"app_id\", \"app_name\", \"review_votes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f5b54c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:16.551900Z",
     "start_time": "2024-03-31T14:53:16.537591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                         review_text  review_score\n0                                Early Access Review             1\n1  PAYDAY 2 is an action-packed, four-player co-o...             1\n2                                Early Access Review             1\n3                                Early Access Review             1\n4  This is my first diccusion and hope it don't h...            -1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_text</th>\n      <th>review_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PAYDAY 2 is an action-packed, four-player co-o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This is my first diccusion and hope it don't h...</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d13f1",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb2af120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:36.781274Z",
     "start_time": "2024-03-31T14:53:16.554003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0                              [early, access, review]\n1    [payday, is, an, action, packed, four, player,...\n2                              [early, access, review]\n3                              [early, access, review]\n4    [this, is, my, first, diccusion, and, hope, it...\nName: tokenized_text, dtype: object"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_text(df_to_tokenise, text_column, tokenized_text_column):\n",
    "    from gensim.utils import simple_preprocess\n",
    "    import string\n",
    "    df_to_tokenise[text_column] = [\"\".join([(ch if ch not in string.punctuation else \" \") for ch in line]) for line in df_to_tokenise[text_column]]\n",
    "    # Tokenize the text column to get the new column 'tokenized_text'\n",
    "    df_to_tokenise[tokenized_text_column] = [simple_preprocess(line, deacc=True) for line in df_to_tokenise[text_column]]\n",
    "    return df_to_tokenise\n",
    "    \n",
    "df_cleaned = tokenize_text(df_cleaned, 'review_text', 'tokenized_text')\n",
    "df_cleaned['tokenized_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c96433",
   "metadata": {},
   "source": [
    "# Stemming & Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c904fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:36.813588Z",
     "start_time": "2024-03-31T14:53:36.783785Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_be_stemmed = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d4957",
   "metadata": {},
   "source": [
    "### PoterStammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad6379b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:36.828669Z",
     "start_time": "2024-03-31T14:53:36.815142Z"
    }
   },
   "outputs": [],
   "source": [
    "def porter_stemmer_on_text(df_to_be_stemmed, token_text_column, stemmed_text_column):\n",
    "    from gensim.parsing.porter import PorterStemmer\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    df_potter_stemmed = df_to_be_stemmed.copy()\n",
    "    # Get the stemmed_tokens\n",
    "    df_potter_stemmed[stemmed_text_column] = [[porter_stemmer.stem(word) for word in tokens] \n",
    "                                        for tokens in df_potter_stemmed[token_text_column]]  \n",
    "    return df_potter_stemmed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748fc115",
   "metadata": {},
   "source": [
    "### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0011d84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:36.844001Z",
     "start_time": "2024-03-31T14:53:36.829715Z"
    }
   },
   "outputs": [],
   "source": [
    "def lancaster_stemmer_on_text(df_to_be_stemmed, token_text_column, stemmed_text_column):\n",
    "    from nltk.stem.lancaster import LancasterStemmer\n",
    "    lancaster_stemmer = LancasterStemmer()\n",
    "    df_lancaster_stemmed = df_to_be_stemmed.copy()\n",
    "    # Get the stemmed_tokens\n",
    "    df_lancaster_stemmed[stemmed_text_column] = [[lancaster_stemmer.stem(word) for word in tokens] \n",
    "                                        for tokens in df_lancaster_stemmed[token_text_column]]\n",
    "    \n",
    "    return df_lancaster_stemmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424002e9",
   "metadata": {},
   "source": [
    "### Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4020d6fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:36.859417Z",
     "start_time": "2024-03-31T14:53:36.845063Z"
    }
   },
   "outputs": [],
   "source": [
    "def snowball_stemmer_on_text(df_to_be_stemmed, token_text_column, stemmed_text_column):\n",
    "    from nltk.stem.snowball import EnglishStemmer\n",
    "    snowball_stemmer = EnglishStemmer()\n",
    "    df_snowball_stemmed = df_to_be_stemmed.copy()\n",
    "    # Get the stemmed_tokens\n",
    "    df_snowball_stemmed[stemmed_text_column] = [[snowball_stemmer.stem(word) for word in tokens] \n",
    "                                        for tokens in df_snowball_stemmed[token_text_column]]\n",
    "    \n",
    "    return df_snowball_stemmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453e96e",
   "metadata": {},
   "source": [
    "### Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c4ab77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:36.875352Z",
     "start_time": "2024-03-31T14:53:36.860459Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_text(df_to_be_stemmed, token_text_column, lemmatized_text_column):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    df_lemmatized = df_to_be_stemmed.copy()\n",
    "    \n",
    "    # Get the lemmatized_tokens\n",
    "    df_lemmatized[lemmatized_text_column] = [[wordnet_lemmatizer.lemmatize(word) for word in tokens] \n",
    "                                          for tokens in df_lemmatized[token_text_column]]\n",
    "    \n",
    "    return df_lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f40c074b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:54:08.910686Z",
     "start_time": "2024-03-31T14:53:36.876395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                         review_text  review_score  \\\n0                                Early Access Review             1   \n1  PAYDAY 2 is an action packed  four player co o...             1   \n2                                Early Access Review             1   \n3                                Early Access Review             1   \n4  This is my first diccusion and hope it don t h...            -1   \n5                                Early Access Review             1   \n6                            Uplay  More like Udont             -1   \n7  This game doesn t even start  Don t bother wit...            -1   \n8                                Early Access Review            -1   \n9  Its like someone played Guacamelee and made an...            -1   \n\n                                      tokenized_text  \\\n0                            [early, access, review]   \n1  [payday, is, an, action, packed, four, player,...   \n2                            [early, access, review]   \n3                            [early, access, review]   \n4  [this, is, my, first, diccusion, and, hope, it...   \n5                            [early, access, review]   \n6                         [uplay, more, like, udont]   \n7  [this, game, doesn, even, start, don, bother, ...   \n8                            [early, access, review]   \n9  [its, like, someone, played, guacamelee, and, ...   \n\n                                        stemmed_text  \n0                            [earli, access, review]  \n1  [paydai, is, an, action, pack, four, player, c...  \n2                            [earli, access, review]  \n3                            [earli, access, review]  \n4  [thi, is, my, first, diccus, and, hope, it, do...  \n5                            [earli, access, review]  \n6                         [uplai, more, like, udont]  \n7  [thi, game, doesn, even, start, don, bother, w...  \n8                            [earli, access, review]  \n9  [it, like, someon, plai, guacamele, and, made,...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_text</th>\n      <th>review_score</th>\n      <th>tokenized_text</th>\n      <th>stemmed_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>[early, access, review]</td>\n      <td>[earli, access, review]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PAYDAY 2 is an action packed  four player co o...</td>\n      <td>1</td>\n      <td>[payday, is, an, action, packed, four, player,...</td>\n      <td>[paydai, is, an, action, pack, four, player, c...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>[early, access, review]</td>\n      <td>[earli, access, review]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>[early, access, review]</td>\n      <td>[earli, access, review]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This is my first diccusion and hope it don t h...</td>\n      <td>-1</td>\n      <td>[this, is, my, first, diccusion, and, hope, it...</td>\n      <td>[thi, is, my, first, diccus, and, hope, it, do...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>[early, access, review]</td>\n      <td>[earli, access, review]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Uplay  More like Udont</td>\n      <td>-1</td>\n      <td>[uplay, more, like, udont]</td>\n      <td>[uplai, more, like, udont]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>This game doesn t even start  Don t bother wit...</td>\n      <td>-1</td>\n      <td>[this, game, doesn, even, start, don, bother, ...</td>\n      <td>[thi, game, doesn, even, start, don, bother, w...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Early Access Review</td>\n      <td>-1</td>\n      <td>[early, access, review]</td>\n      <td>[earli, access, review]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Its like someone played Guacamelee and made an...</td>\n      <td>-1</td>\n      <td>[its, like, someone, played, guacamelee, and, ...</td>\n      <td>[it, like, someon, plai, guacamele, and, made,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_potter_stemmed = porter_stemmer_on_text(df_to_be_stemmed, 'tokenized_text', 'stemmed_text')\n",
    "df_potter_stemmed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e0074",
   "metadata": {},
   "source": [
    "## Split into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643bda16",
   "metadata": {},
   "source": [
    "- Train data ( Subset of data for training ML Model) ~70%\n",
    "- Test data (Subset of data for testing ML Model trained from the train data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e99184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:54:09.052442Z",
     "start_time": "2024-03-31T14:54:08.912205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train sentiments\n",
      "review_score\n",
      " 1    58126\n",
      "-1    54644\n",
      "Name: count, dtype: int64\n",
      "Value counts for Test sentiments\n",
      "review_score\n",
      " 1    24887\n",
      "-1    23444\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "    index                                       stemmed_text\n",
      "0   79666  [quit, possibl, the, best, propaganda, in, the...\n",
      "1   39512  [best, game, ever, for, real, am, pretti, sure...\n",
      "2   27798                                        [top, game]\n",
      "3   68251                                    [steam, econom]\n",
      "4  110354  [back, in, dai, decid, to, bui, lego, game, to...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test(data, sentiment_value_col, tokenised_text_col, test_size=0.3, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( data[tokenised_text_col],\n",
    "                                                        data[sentiment_value_col], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(df_potter_stemmed, 'review_score', 'stemmed_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c2ac1",
   "metadata": {},
   "source": [
    "# Word2Vec "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339bfb7",
   "metadata": {},
   "source": [
    "## Save-gram approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87617e6",
   "metadata": {},
   "source": [
    "### Generate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76083db",
   "metadata": {},
   "source": [
    "vector_size (int, optional) – Dimensionality of the word vectors.\n",
    "\n",
    "window (int, optional) – Maximum distance between the current and predicted word within a sentence.\n",
    "\n",
    "min_count (int, optional) – Ignores all words with total frequency lower than this.\n",
    "\n",
    "workers (int, optional) – Use these many worker threads to train the model (=faster training with multicore machines).\n",
    "\n",
    "sg ({0, 1}, optional) – Training algorithm: 1 for skip-gram; otherwise CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16df688c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:54:44.800676Z",
     "start_time": "2024-03-31T14:54:09.053443Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_word2vec_model(stemmed_df, file_name_code, stem_column_name, sg, vector_size, window, min_count, workers):\n",
    "    from gensim.models import Word2Vec\n",
    "    # Skip-gram model (sg = 1)\n",
    "    filename = f\"{file_name_code}_wind_{window}_min_{min_count}_workers_{workers}.wordvectors\"\n",
    "    stemmed_tokens = pd.Series(stemmed_df[stem_column_name]).values\n",
    "    # Train the Word2Vec Model\n",
    "    w2v_model = Word2Vec(stemmed_tokens, min_count = min_count, vector_size = vector_size, workers = workers, window = window, sg = sg, cbow_mean = 1)\n",
    "    w2v_model_wv_fn = w2v_model.wv\n",
    "    w2v_model_wv_fn.save(OUTPUT_FOLDER + filename)\n",
    "\n",
    "    return w2v_model_wv_fn, OUTPUT_FOLDER + filename\n",
    "\n",
    "vector_size = 100\n",
    "sg = 1\n",
    "file_name_code = f\"_cs3244_steam_vec_sz_{vector_size}_sg_{sg}_frac_pop_{frac_pop}\"\n",
    "OUTPUT_FOLDER = 'model/' + file_name_code + '/'\n",
    "import os\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "w2v_model_wv, output_name = generate_word2vec_model(df_potter_stemmed, file_name_code,'stemmed_text', sg = sg, vector_size=vector_size, min_count=1, window=8, workers=100)\n",
    "\n",
    "# print(w2v_model_cbow_wv.most_similar('good'))\n",
    "# print(w2v_model_sg_wv.most_similar('good'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d34b8",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d749099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:54:44.847153Z",
     "start_time": "2024-03-31T14:54:44.801715Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Load the model from the model file\n",
    "\n",
    "def load_word2vec_model(reduced_mode_file, stem_column_name):\n",
    "    sg_w2v_model_wv = KeyedVectors.load(reduced_mode_file)\n",
    "    # # Unique ID of the word\n",
    "    # print(\"Index of the word 'action':\")\n",
    "    # print(sg_w2v_model_wv.key_to_index[\"action\"])\n",
    "    # # Total number of the words\n",
    "    # print(len(sg_w2v_model_wv.key_to_index))\n",
    "    # # Print the size of the word2vec vector for one word\n",
    "    # print(\"Length of the vector generated for a word\")\n",
    "    # print(len(sg_w2v_model_wv['action']))\n",
    "    # # Get the mean for the vectors for an example review\n",
    "    # print(\"Print the length after taking average of all word vectors in a sentence:\")\n",
    "    # print(np.mean([sg_w2v_model_wv[token] for token in df_potter_stemmed[stem_column_name][0]], axis=0))\n",
    "    return sg_w2v_model_wv\n",
    "    \n",
    "w2v_model_wv = load_word2vec_model(output_name, 'stemmed_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9be7ef6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:55:18.959445Z",
     "start_time": "2024-03-31T14:54:44.848187Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nam\\Documents\\CS3244\\GroupProject\\Sentimentalyst\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Nam\\Documents\\CS3244\\GroupProject\\Sentimentalyst\\.venv\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def save_word2vec_to_csv(X_set, sg_w2v_model_wv, stem_col, word2vec_filename):\n",
    "    with open(word2vec_filename, 'w+') as word2vec_file:\n",
    "        for index, row in X_set.iterrows():\n",
    "            v_norm = (np.mean([sg_w2v_model_wv[token] for token in row[stem_col]], axis=0)).tolist()\n",
    "            if index == 0:\n",
    "                header = \",\".join(str(ele) for ele in range(vector_size))\n",
    "                word2vec_file.write(header)\n",
    "                word2vec_file.write(\"\\n\")\n",
    "            # Check if the line exists else it is vector of zeros\n",
    "            if type(v_norm) is list:  \n",
    "                line1 = \",\".join( [str(vector_element) for vector_element in v_norm] )\n",
    "            else:\n",
    "                line1 = \",\".join([str(0) for i in range(vector_size)])\n",
    "            word2vec_file.write(line1)\n",
    "            word2vec_file.write('\\n')\n",
    "           \n",
    "\n",
    "    \n",
    "train_X_word2vec_filename = OUTPUT_FOLDER +  f\"train_X_{file_name_code}.csv\"\n",
    "test_X_word2vec_filename = OUTPUT_FOLDER + f\"test_X_{file_name_code}.csv\"\n",
    "\n",
    "\n",
    "save_word2vec_to_csv(X_train, w2v_model_wv, \"stemmed_text\", train_X_word2vec_filename)\n",
    "save_word2vec_to_csv(X_test, w2v_model_wv, \"stemmed_text\", test_X_word2vec_filename)\n",
    "\n",
    "# save_word2vec_to_csv(X_train, w2v_model_cbow_wv, \"stemmed_text\", train_X_word2vec_cbow_filename)\n",
    "# save_word2vec_to_csv(X_test, w2v_model_cbow_wv, \"stemmed_text\", test_X_word2vec_cbow_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d30c3b",
   "metadata": {},
   "source": [
    "## Load Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11a6e9d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:55:21.370259Z",
     "start_time": "2024-03-31T14:55:18.960406Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_train_w2v_from_csv(word2vec_filename):\n",
    "    train_word2vec_df = pd.read_csv(word2vec_filename)\n",
    "    return train_word2vec_df\n",
    "\n",
    "def load_test_wv_w2v_from_csv(test_X_word2vec_filename):\n",
    "    return pd.read_csv(test_X_word2vec_filename)\n",
    "\n",
    "def generate_X_w2v_df(X_set, w2v_model_wv, stem_column_name):\n",
    "    X_wv = []\n",
    "    for index, row in X_set.iterrows():\n",
    "        model_vector = (np.mean([w2v_model_wv[token] for token in row[stem_column_name]], axis=0))\n",
    "        if model_vector.shape == () :\n",
    "            model_vector = np.zeros(vector_size)\n",
    "        X_wv.append(model_vector.reshape(1, -1))\n",
    "    return pd.DataFrame(np.concatenate(X_wv, axis=0))\n",
    "\n",
    "X_train_wv = load_train_w2v_from_csv(train_X_word2vec_filename)\n",
    "X_test_wv = load_test_wv_w2v_from_csv(test_X_word2vec_filename)\n",
    "\n",
    "# X_train_wv = generate_X_w2v_df(X_train, w2v_model_wv, \"stemmed_text\")\n",
    "# X_test_wv = generate_X_w2v_df(X_test, w2v_model_wv, \"stemmed_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c2ebea",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121a4a64",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc03c6c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:55:41.949938Z",
     "start_time": "2024-03-31T14:55:21.371306Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_decision_tree_word2vec(X_train_wv, Y_train, col_name, file_name_code):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    #Initialize the model\n",
    "    clf_decision_word2vec = DecisionTreeClassifier()\n",
    "    # Fit the model\n",
    "    clf_decision_word2vec.fit(X_train_wv, Y_train['review_score'])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(clf_decision_word2vec, OUTPUT_FOLDER + f'clf_dt_cbow_{file_name_code}.pkl')\n",
    "\n",
    "    return clf_decision_word2vec\n",
    "\n",
    "clf_decision_word2vec = train_decision_tree_word2vec(X_train_wv, Y_train, 'review_score', file_name_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25b987",
   "metadata": {},
   "source": [
    "Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb353250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:55:42.043268Z",
     "start_time": "2024-03-31T14:55:41.950963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.68      0.69     23444\n",
      "           1       0.70      0.72      0.71     24887\n",
      "\n",
      "    accuracy                           0.70     48331\n",
      "   macro avg       0.70      0.70      0.70     48331\n",
      "weighted avg       0.70      0.70      0.70     48331\n"
     ]
    }
   ],
   "source": [
    "def test_decision_tree_word2vec(Y_test, X_test_wv, col_name, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    test_predictions_word2vec = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test[col_name], test_predictions_word2vec))\n",
    "\n",
    "test_decision_tree_word2vec(Y_test, X_test_wv, \"review_score\", clf_decision_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d0097b",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02dbe03",
   "metadata": {},
   "source": [
    "### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe2254ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:56:04.724010Z",
     "start_time": "2024-03-31T14:55:42.044305Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nam\\Documents\\CS3244\\GroupProject\\Sentimentalyst\\.venv\\lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def train_linear_svc(X_train_wv, Y_train, col_name, file_name_code):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    #Initialize the model\n",
    "    clf_decision_word2vec = LinearSVC()\n",
    "    # Fit the model\n",
    "    clf_decision_word2vec.fit(X_train_wv, Y_train[col_name])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(clf_decision_word2vec, OUTPUT_FOLDER + f'l_svc_{file_name_code}.pkl')\n",
    "\n",
    "    return clf_decision_word2vec\n",
    "\n",
    "svc_clf = train_linear_svc(X_train_wv, Y_train, \"review_score\", file_name_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e4257f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:56:04.788009Z",
     "start_time": "2024-03-31T14:56:04.725007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.83      0.82     23444\n",
      "           1       0.84      0.81      0.82     24887\n",
      "\n",
      "    accuracy                           0.82     48331\n",
      "   macro avg       0.82      0.82      0.82     48331\n",
      "weighted avg       0.82      0.82      0.82     48331\n"
     ]
    }
   ],
   "source": [
    "def test_linear_svc(Y_test, X_test_wv, col_name, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    test_predictions_word2vec = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test[col_name], test_predictions_word2vec))\n",
    "\n",
    "test_linear_svc(Y_test, X_test_wv, \"review_score\", svc_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scaled"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c99f7fe94a027ebd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nam\\Documents\\CS3244\\GroupProject\\Sentimentalyst\\.venv\\lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nam\\Documents\\CS3244\\GroupProject\\Sentimentalyst\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def train_linear_svc_scaled(X_train_wv, Y_train, col_name, file_name_code):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    #Initialize the model\n",
    "    clf = make_pipeline(StandardScaler(), LinearSVC())\n",
    "    # Fit the model\n",
    "    clf.fit(X_train_wv, Y_train[col_name])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(clf, OUTPUT_FOLDER + f'l_svc_scl_{file_name_code}.pkl')\n",
    "\n",
    "    return clf\n",
    "\n",
    "svc_clf = train_linear_svc_scaled(X_train_wv, Y_train, \"review_score\", file_name_code)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:56:59.377463Z",
     "start_time": "2024-03-31T14:56:04.789009Z"
    }
   },
   "id": "de0ec668ce503715",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.83      0.82     23444\n",
      "           1       0.84      0.81      0.82     24887\n",
      "\n",
      "    accuracy                           0.82     48331\n",
      "   macro avg       0.82      0.82      0.82     48331\n",
      "weighted avg       0.82      0.82      0.82     48331\n"
     ]
    }
   ],
   "source": [
    "def test_linear_svc_scaled(Y_test, X_test_wv, col_name, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    test_predictions_word2vec_svm_scaled = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test[col_name], test_predictions_word2vec_svm_scaled))\n",
    "    \n",
    "test_linear_svc_scaled(Y_test, X_test_wv, \"review_score\", svc_clf)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:56:59.464229Z",
     "start_time": "2024-03-31T14:56:59.378463Z"
    }
   },
   "id": "57e7e79b0a740316",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "cffd2d42",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba1cda2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:59:12.248343Z",
     "start_time": "2024-03-31T14:56:59.465227Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_random_forest_clf(X_train_wv, Y_train, col_name, file_name_code):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    #Initialize the model\n",
    "    clf_decision_word2vec = RandomForestClassifier()\n",
    "    # Fit the model\n",
    "    clf_decision_word2vec.fit(X_train_wv, Y_train[col_name])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(clf_decision_word2vec, OUTPUT_FOLDER + f'random_forest_dt_clf_{file_name_code}.pkl')\n",
    "\n",
    "    return clf_decision_word2vec\n",
    "\n",
    "clf_rfdt = train_random_forest_clf(X_train_wv, Y_train, \"review_score\", file_name_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af327203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T14:59:13.548796Z",
     "start_time": "2024-03-31T14:59:12.251335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.81      0.80     23444\n",
      "           1       0.82      0.80      0.81     24887\n",
      "\n",
      "    accuracy                           0.81     48331\n",
      "   macro avg       0.81      0.81      0.81     48331\n",
      "weighted avg       0.81      0.81      0.81     48331\n"
     ]
    }
   ],
   "source": [
    "def test_random_forest_clf(Y_test, X_test_wv, col_name, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    # from joblib import load\n",
    "    # clf = load(OUTPUT_FOLDER + 'svm_classifier_scl_linear.pkl')\n",
    "    test_predictions_word2vec_svm_scaled = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test[col_name], test_predictions_word2vec_svm_scaled))\n",
    "\n",
    "test_random_forest_clf(Y_test, X_test_wv, \"review_score\", clf_rfdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3fae3",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "773e7cf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T15:00:39.674590Z",
     "start_time": "2024-03-31T14:59:13.549798Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nam\\Documents\\CS3244\\GroupProject\\Sentimentalyst\\.venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def train_adab_clf(X_train_wv, Y_train, col_name, file_name_code):\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    #Initialize the model\n",
    "    adab_clf = AdaBoostClassifier()\n",
    "    # Fit the model\n",
    "    adab_clf.fit(X_train_wv, Y_train[col_name])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(adab_clf, OUTPUT_FOLDER + f'adab_clf_{file_name_code}.pkl')\n",
    "\n",
    "    return adab_clf\n",
    "\n",
    "adab_clf = train_adab_clf(X_train_wv, Y_train, \"review_score\", file_name_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5499df0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T15:00:40.537610Z",
     "start_time": "2024-03-31T15:00:39.675590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.78      0.78     23444\n",
      "           1       0.79      0.79      0.79     24887\n",
      "\n",
      "    accuracy                           0.78     48331\n",
      "   macro avg       0.78      0.78      0.78     48331\n",
      "weighted avg       0.78      0.78      0.78     48331\n"
     ]
    }
   ],
   "source": [
    "def test_adab_clf(Y_test, X_test_wv, col_name, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    # from joblib import load\n",
    "    # clf = load(OUTPUT_FOLDER + 'svm_classifier_scl_linear.pkl')\n",
    "    test_predictions_word2vec_svm_scaled = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test[col_name], test_predictions_word2vec_svm_scaled))\n",
    "    \n",
    "test_adab_clf(Y_test, X_test_wv, \"review_score\", adab_clf)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b172c",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6da220e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T15:02:30.074079Z",
     "start_time": "2024-03-31T15:00:40.538612Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nam\\Documents\\CS3244\\GroupProject\\Sentimentalyst\\.venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def train_mlp_clf(X_train_wv, Y_train, col_name, file_name_code):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    #Initialize the model\n",
    "    mlp_clf = MLPClassifier()\n",
    "    # Fit the model\n",
    "    mlp_clf.fit(X_train_wv, Y_train[col_name])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(mlp_clf, OUTPUT_FOLDER + f'mlp_clf_{file_name_code}.pkl')\n",
    "\n",
    "    return mlp_clf\n",
    "\n",
    "mlp_clf = train_mlp_clf(X_train_wv, Y_train, \"review_score\", file_name_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fb4ca54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T15:02:30.964074Z",
     "start_time": "2024-03-31T15:02:30.077076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.78      0.78     23444\n",
      "           1       0.79      0.79      0.79     24887\n",
      "\n",
      "    accuracy                           0.78     48331\n",
      "   macro avg       0.78      0.78      0.78     48331\n",
      "weighted avg       0.78      0.78      0.78     48331\n"
     ]
    }
   ],
   "source": [
    "def test_mlp_clf(Y_test, X_test_wv, col_name, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    # from joblib import load\n",
    "    # clf = load(OUTPUT_FOLDER + 'svm_classifier_scl_linear.pkl')\n",
    "    test_predictions_word2vec_svm_scaled = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test[col_name], test_predictions_word2vec_svm_scaled))\n",
    "    \n",
    "test_mlp_clf(Y_test, X_test_wv, \"review_score\", adab_clf)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776076fb",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a810f5ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T15:02:31.187075Z",
     "start_time": "2024-03-31T15:02:30.965074Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_naive_bay(X_train_wv, Y_train, col_name, file_name_code):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #Initialize the model\n",
    "    clf_decision_word2vec = GaussianNB()\n",
    "    # Fit the model\n",
    "    clf_decision_word2vec.fit(X_train_wv, Y_train[col_name])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(clf_decision_word2vec, OUTPUT_FOLDER + f'gauss_NB_{file_name_code}.pkl')\n",
    "\n",
    "    return clf_decision_word2vec\n",
    "\n",
    "svc_clf = train_naive_bay(X_train_wv, Y_train, \"review_score\", file_name_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18f7a4c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T15:02:31.361687Z",
     "start_time": "2024-03-31T15:02:31.188077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.61      0.85      0.71     23444\n",
      "           1       0.77      0.49      0.60     24887\n",
      "\n",
      "    accuracy                           0.66     48331\n",
      "   macro avg       0.69      0.67      0.65     48331\n",
      "weighted avg       0.69      0.66      0.65     48331\n"
     ]
    }
   ],
   "source": [
    "def test_naive_bay(Y_test, X_test_wv, col_name, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    test_predictions_word2vec = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test[col_name], test_predictions_word2vec))\n",
    "\n",
    "test_naive_bay(Y_test, X_test_wv, \"review_score\", svc_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24263449",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce202bc",
   "metadata": {},
   "source": [
    "\n",
    "## Trial 1 26/3/2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d5879",
   "metadata": {},
   "source": [
    "- vector size = 100\n",
    "- sg = 1\n",
    "- frac_pop = 1\n",
    "- porter stemmer\n",
    "\n",
    "W2V size = 90KB\n",
    "\n",
    "|Model name | Setting | F1 | Accuracy | Size|\n",
    "|-----------|----------|----|----------|------|\n",
    "|Decision tree | DEFAULT | 0.66 | 0.66| 19,000 KB|\n",
    "|Linear SVC | DEFAULT | 0.76 | 0.76 | 3KB |\n",
    "|Random Forest | DEFAULT | 0.76 | 0.76 | 1.9e6 KB|\n",
    "|Gauss NB| DEFAULT | 0.70\\0.60 | 0.66 | 6KB |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3591d5ed",
   "metadata": {},
   "source": [
    "## Trial 2 26/3/2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8606071",
   "metadata": {},
   "source": [
    "Nothing different from trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "327da73c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T15:02:31.377662Z",
     "start_time": "2024-03-31T15:02:31.362663Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0776796b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T15:02:31.392664Z",
     "start_time": "2024-03-31T15:02:31.378662Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
