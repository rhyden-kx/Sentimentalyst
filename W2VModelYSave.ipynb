{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b21851e",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db03b82-98d8-40dd-ae5f-96b4f256536e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:14:56.270429Z",
     "start_time": "2024-04-01T13:14:51.378434Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUTPUT_FOLDER = 'model/'\n",
    "\n",
    "seed = 88\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6de5829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:14:57.405433Z",
     "start_time": "2024-04-01T13:14:56.272430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file with specified column names\n",
    "df = pd.read_csv(\"dataset/steam_dataset_200000.csv\", index_col= 0)\n",
    "\n",
    "def reduce_sample(df_sample, frac, random_state):\n",
    "    df_sample = df_sample.sample(frac=frac, random_state=random_state)\n",
    "    df_sample = df_sample.reset_index(drop=True)\n",
    "    return df_sample\n",
    "frac_pop = 1\n",
    "df = reduce_sample(df, frac_pop, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6aa034",
   "metadata": {},
   "source": [
    "Columns in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477335fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:14:57.412431Z",
     "start_time": "2024-04-01T13:14:57.406433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the original dataset:\n",
      "\n",
      "Index(['app_id', 'app_name', 'review_text', 'review_score', 'review_votes'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in the original dataset:\\n\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2a23b",
   "metadata": {},
   "source": [
    "Example of a Row in dataset"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   app_id               app_name  \\\n0  322330  Don't Starve Together   \n1  218620               PAYDAY 2   \n2  372800                 RPG MO   \n3  453090              Parkitect   \n4  236390            War Thunder   \n\n                                         review_text  review_score  \\\n0                                Early Access Review             1   \n1  PAYDAY 2 is an action-packed, four-player co-o...             1   \n2                                Early Access Review             1   \n3                                Early Access Review             1   \n4  This is my first diccusion and hope it don't h...            -1   \n\n   review_votes  \n0             0  \n1             0  \n2             0  \n3             0  \n4             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>app_id</th>\n      <th>app_name</th>\n      <th>review_text</th>\n      <th>review_score</th>\n      <th>review_votes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>322330</td>\n      <td>Don't Starve Together</td>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>218620</td>\n      <td>PAYDAY 2</td>\n      <td>PAYDAY 2 is an action-packed, four-player co-o...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>372800</td>\n      <td>RPG MO</td>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>453090</td>\n      <td>Parkitect</td>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>236390</td>\n      <td>War Thunder</td>\n      <td>This is my first diccusion and hope it don't h...</td>\n      <td>-1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:14:57.444429Z",
     "start_time": "2024-04-01T13:14:57.413433Z"
    }
   },
   "id": "5553cabf15b246e3",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689c8807",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:14:57.455437Z",
     "start_time": "2024-04-01T13:14:57.446432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "review_score\n 1    100000\n-1    100000\nName: count, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d146b21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:14:57.494431Z",
     "start_time": "2024-04-01T13:14:57.457434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              app_id   review_score   review_votes\ncount  200000.000000  200000.000000  200000.000000\nmean   235172.063805       0.000000       0.183330\nstd    123389.931619       1.000003       0.386938\nmin        10.000000      -1.000000       0.000000\n25%    206420.000000      -1.000000       0.000000\n50%    244210.000000       0.000000       0.000000\n75%    311240.000000       1.000000       0.000000\nmax    562710.000000       1.000000       1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>app_id</th>\n      <th>review_score</th>\n      <th>review_votes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>200000.000000</td>\n      <td>200000.000000</td>\n      <td>200000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>235172.063805</td>\n      <td>0.000000</td>\n      <td>0.183330</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>123389.931619</td>\n      <td>1.000003</td>\n      <td>0.386938</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>10.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>206420.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>244210.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>311240.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>562710.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa9c1c4",
   "metadata": {},
   "source": [
    "Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c21871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:14:57.847430Z",
     "start_time": "2024-04-01T13:14:57.495433Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_dataset(df_to_clean, drop_columns):\n",
    "    df_to_clean = df_to_clean.dropna()\n",
    "    df_to_clean = df_to_clean.drop_duplicates()\n",
    "    df_to_clean = df_to_clean.drop(columns=drop_columns)\n",
    "    df_to_clean = df_to_clean.reset_index(drop=True)\n",
    "    df_to_clean.describe()\n",
    "    return df_to_clean\n",
    "\n",
    "df_cleaned = clean_dataset(df, [\"app_id\", \"app_name\", \"review_votes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f5b54c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:14:57.856431Z",
     "start_time": "2024-04-01T13:14:57.848433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                         review_text  review_score\n0                                Early Access Review             1\n1  PAYDAY 2 is an action-packed, four-player co-o...             1\n2                                Early Access Review             1\n3                                Early Access Review             1\n4  This is my first diccusion and hope it don't h...            -1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_text</th>\n      <th>review_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PAYDAY 2 is an action-packed, four-player co-o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This is my first diccusion and hope it don't h...</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d13f1",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb2af120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:15:26.273195Z",
     "start_time": "2024-04-01T13:14:57.858431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0                              [early, access, review]\n1    [payday, is, an, action, packed, four, player,...\n2                              [early, access, review]\n3                              [early, access, review]\n4    [this, is, my, first, diccusion, and, hope, it...\nName: tokenized_text, dtype: object"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_text(df_to_tokenise, text_column, tokenized_text_column):\n",
    "    from gensim.utils import simple_preprocess\n",
    "    import string\n",
    "    df_to_tokenise[text_column] = [\"\".join([(ch if ch not in string.punctuation else \" \") for ch in line]) for line in df_to_tokenise[text_column]]\n",
    "    # Tokenize the text column to get the new column 'tokenized_text'\n",
    "    df_to_tokenise[tokenized_text_column] = [simple_preprocess(line, deacc=True) for line in df_to_tokenise[text_column]]\n",
    "    return df_to_tokenise\n",
    "    \n",
    "df_cleaned = tokenize_text(df_cleaned, 'review_text', 'tokenized_text')\n",
    "df_cleaned['tokenized_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c96433",
   "metadata": {},
   "source": [
    "# Stemming & Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c904fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:15:26.304195Z",
     "start_time": "2024-04-01T13:15:26.274196Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_be_stemmed = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d4957",
   "metadata": {},
   "source": [
    "### PoterStammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad6379b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:15:26.311193Z",
     "start_time": "2024-04-01T13:15:26.305196Z"
    }
   },
   "outputs": [],
   "source": [
    "def porter_stemmer_on_text(df_to_be_stemmed, token_text_column, stemmed_text_column):\n",
    "    from gensim.parsing.porter import PorterStemmer\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    df_potter_stemmed = df_to_be_stemmed.copy()\n",
    "    # Get the stemmed_tokens\n",
    "    df_potter_stemmed[stemmed_text_column] = [[porter_stemmer.stem(word) for word in tokens] \n",
    "                                        for tokens in df_potter_stemmed[token_text_column]]  \n",
    "    return df_potter_stemmed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748fc115",
   "metadata": {},
   "source": [
    "### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0011d84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:15:26.320194Z",
     "start_time": "2024-04-01T13:15:26.312194Z"
    }
   },
   "outputs": [],
   "source": [
    "def lancaster_stemmer_on_text(df_to_be_stemmed, token_text_column, stemmed_text_column):\n",
    "    from nltk.stem.lancaster import LancasterStemmer\n",
    "    lancaster_stemmer = LancasterStemmer()\n",
    "    df_lancaster_stemmed = df_to_be_stemmed.copy()\n",
    "    # Get the stemmed_tokens\n",
    "    df_lancaster_stemmed[stemmed_text_column] = [[lancaster_stemmer.stem(word) for word in tokens] \n",
    "                                        for tokens in df_lancaster_stemmed[token_text_column]]\n",
    "    \n",
    "    return df_lancaster_stemmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424002e9",
   "metadata": {},
   "source": [
    "### Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4020d6fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:15:26.328194Z",
     "start_time": "2024-04-01T13:15:26.321197Z"
    }
   },
   "outputs": [],
   "source": [
    "def snowball_stemmer_on_text(df_to_be_stemmed, token_text_column, stemmed_text_column):\n",
    "    from nltk.stem.snowball import EnglishStemmer\n",
    "    snowball_stemmer = EnglishStemmer()\n",
    "    df_snowball_stemmed = df_to_be_stemmed.copy()\n",
    "    # Get the stemmed_tokens\n",
    "    df_snowball_stemmed[stemmed_text_column] = [[snowball_stemmer.stem(word) for word in tokens] \n",
    "                                        for tokens in df_snowball_stemmed[token_text_column]]\n",
    "    \n",
    "    return df_snowball_stemmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453e96e",
   "metadata": {},
   "source": [
    "### Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c4ab77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:15:26.349196Z",
     "start_time": "2024-04-01T13:15:26.331195Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_text(df_to_be_stemmed, token_text_column, lemmatized_text_column):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    df_lemmatized = df_to_be_stemmed.copy()\n",
    "    \n",
    "    # Get the lemmatized_tokens\n",
    "    df_lemmatized[lemmatized_text_column] = [[wordnet_lemmatizer.lemmatize(word) for word in tokens] \n",
    "                                          for tokens in df_lemmatized[token_text_column]]\n",
    "    \n",
    "    return df_lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f40c074b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:15:58.161967Z",
     "start_time": "2024-04-01T13:15:26.351198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                         review_text  review_score  \\\n0                                Early Access Review             1   \n1  PAYDAY 2 is an action packed  four player co o...             1   \n2                                Early Access Review             1   \n3                                Early Access Review             1   \n4  This is my first diccusion and hope it don t h...            -1   \n5                                Early Access Review             1   \n6                            Uplay  More like Udont             -1   \n7  This game doesn t even start  Don t bother wit...            -1   \n8                                Early Access Review            -1   \n9  Its like someone played Guacamelee and made an...            -1   \n\n                                      tokenized_text  \\\n0                            [early, access, review]   \n1  [payday, is, an, action, packed, four, player,...   \n2                            [early, access, review]   \n3                            [early, access, review]   \n4  [this, is, my, first, diccusion, and, hope, it...   \n5                            [early, access, review]   \n6                         [uplay, more, like, udont]   \n7  [this, game, doesn, even, start, don, bother, ...   \n8                            [early, access, review]   \n9  [its, like, someone, played, guacamelee, and, ...   \n\n                                        stemmed_text  \n0                            [earli, access, review]  \n1  [paydai, is, an, action, pack, four, player, c...  \n2                            [earli, access, review]  \n3                            [earli, access, review]  \n4  [thi, is, my, first, diccus, and, hope, it, do...  \n5                            [earli, access, review]  \n6                         [uplai, more, like, udont]  \n7  [thi, game, doesn, even, start, don, bother, w...  \n8                            [earli, access, review]  \n9  [it, like, someon, plai, guacamele, and, made,...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_text</th>\n      <th>review_score</th>\n      <th>tokenized_text</th>\n      <th>stemmed_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>[early, access, review]</td>\n      <td>[earli, access, review]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PAYDAY 2 is an action packed  four player co o...</td>\n      <td>1</td>\n      <td>[payday, is, an, action, packed, four, player,...</td>\n      <td>[paydai, is, an, action, pack, four, player, c...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>[early, access, review]</td>\n      <td>[earli, access, review]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>[early, access, review]</td>\n      <td>[earli, access, review]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This is my first diccusion and hope it don t h...</td>\n      <td>-1</td>\n      <td>[this, is, my, first, diccusion, and, hope, it...</td>\n      <td>[thi, is, my, first, diccus, and, hope, it, do...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Early Access Review</td>\n      <td>1</td>\n      <td>[early, access, review]</td>\n      <td>[earli, access, review]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Uplay  More like Udont</td>\n      <td>-1</td>\n      <td>[uplay, more, like, udont]</td>\n      <td>[uplai, more, like, udont]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>This game doesn t even start  Don t bother wit...</td>\n      <td>-1</td>\n      <td>[this, game, doesn, even, start, don, bother, ...</td>\n      <td>[thi, game, doesn, even, start, don, bother, w...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Early Access Review</td>\n      <td>-1</td>\n      <td>[early, access, review]</td>\n      <td>[earli, access, review]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Its like someone played Guacamelee and made an...</td>\n      <td>-1</td>\n      <td>[its, like, someone, played, guacamelee, and, ...</td>\n      <td>[it, like, someon, plai, guacamele, and, made,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_potter_stemmed = porter_stemmer_on_text(df_to_be_stemmed, 'tokenized_text', 'stemmed_text')\n",
    "df_potter_stemmed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e0074",
   "metadata": {},
   "source": [
    "## Split into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643bda16",
   "metadata": {},
   "source": [
    "- Train data ( Subset of data for training ML Model) ~70%\n",
    "- Test data (Subset of data for testing ML Model trained from the train data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e99184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:15:59.764538Z",
     "start_time": "2024-04-01T13:15:58.162973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train sentiments\n",
      "review_score\n",
      " 1    58126\n",
      "-1    54644\n",
      "Name: count, dtype: int64\n",
      "Value counts for Test sentiments\n",
      "review_score\n",
      " 1    24887\n",
      "-1    23444\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "    index                                       stemmed_text\n",
      "0   79666  [quit, possibl, the, best, propaganda, in, the...\n",
      "1   39512  [best, game, ever, for, real, am, pretti, sure...\n",
      "2   27798                                        [top, game]\n",
      "3   68251                                    [steam, econom]\n",
      "4  110354  [back, in, dai, decid, to, bui, lego, game, to...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test(data, sentiment_value_col, tokenised_text_col, test_size=0.3, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( data[tokenised_text_col],\n",
    "                                                        data[sentiment_value_col], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(df_potter_stemmed, 'review_score', 'stemmed_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c2ac1",
   "metadata": {},
   "source": [
    "# Word2Vec "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339bfb7",
   "metadata": {},
   "source": [
    "## Save-gram approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87617e6",
   "metadata": {},
   "source": [
    "### Generate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76083db",
   "metadata": {},
   "source": [
    "vector_size (int, optional) – Dimensionality of the word vectors.\n",
    "\n",
    "window (int, optional) – Maximum distance between the current and predicted word within a sentence.\n",
    "\n",
    "min_count (int, optional) – Ignores all words with total frequency lower than this.\n",
    "\n",
    "workers (int, optional) – Use these many worker threads to train the model (=faster training with multicore machines).\n",
    "\n",
    "sg ({0, 1}, optional) – Training algorithm: 1 for skip-gram; otherwise CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16df688c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:15:59.772539Z",
     "start_time": "2024-04-01T13:15:59.765538Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_word2vec_model(stemmed_df, file_name_code, stem_column_name, sg, vector_size, window, min_count, workers):\n",
    "    from gensim.models import Word2Vec\n",
    "    # Skip-gram model (sg = 1)\n",
    "    filename = f\"{file_name_code}_wind_{window}_min_{min_count}_workers_{workers}.wordvectors\"\n",
    "    stemmed_tokens = pd.Series(stemmed_df[stem_column_name]).values\n",
    "    # Train the Word2Vec Model\n",
    "    w2v_model = Word2Vec(stemmed_tokens, min_count = min_count, vector_size = vector_size, workers = workers, window = window, sg = sg, cbow_mean = 1)\n",
    "    w2v_model_wv_fn = w2v_model.wv\n",
    "    w2v_model_wv_fn.save(OUTPUT_FOLDER + filename)\n",
    "\n",
    "    return w2v_model_wv_fn, OUTPUT_FOLDER + filename\n",
    "\n",
    "vector_size = 100\n",
    "sg = 1\n",
    "file_name_code = f\"_cs3244_steam_vec_sz_{vector_size}_sg_{sg}_frac_pop_{frac_pop}\"\n",
    "OUTPUT_FOLDER = 'model/' + file_name_code + '/'\n",
    "import os\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "\n",
    "# print(w2v_model_cbow_wv.most_similar('good'))\n",
    "# print(w2v_model_sg_wv.most_similar('good'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d34b8",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d749099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:15:59.785537Z",
     "start_time": "2024-04-01T13:15:59.773537Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Load the model from the model file\n",
    "\n",
    "def load_word2vec_model(reduced_mode_file, stem_column_name):\n",
    "    sg_w2v_model_wv = KeyedVectors.load(reduced_mode_file)\n",
    "    # # Unique ID of the word\n",
    "    # print(\"Index of the word 'action':\")\n",
    "    # print(sg_w2v_model_wv.key_to_index[\"action\"])\n",
    "    # # Total number of the words\n",
    "    # print(len(sg_w2v_model_wv.key_to_index))\n",
    "    # # Print the size of the word2vec vector for one word\n",
    "    # print(\"Length of the vector generated for a word\")\n",
    "    # print(len(sg_w2v_model_wv['action']))\n",
    "    # # Get the mean for the vectors for an example review\n",
    "    # print(\"Print the length after taking average of all word vectors in a sentence:\")\n",
    "    # print(np.mean([sg_w2v_model_wv[token] for token in df_potter_stemmed[stem_column_name][0]], axis=0))\n",
    "    return sg_w2v_model_wv\n",
    "# output_name = OUTPUT_FOLDER + f\"cs3244_steam_vec_sz_{vector_size}_sg_{sg}_frac_pop_{frac_pop}.wordvectors\"\n",
    "# w2v_model_wv = load_word2vec_model(output_name, 'stemmed_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9be7ef6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:18:14.518721Z",
     "start_time": "2024-04-01T13:18:10.945718Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_word2vec_to_csv(X_set, sg_w2v_model_wv, stem_col, word2vec_filename):\n",
    "    with open(word2vec_filename, 'w+') as word2vec_file:\n",
    "        for index, row in X_set.iterrows():\n",
    "            v_norm = (np.mean([sg_w2v_model_wv[token] for token in row[stem_col]], axis=0)).tolist()\n",
    "            if index == 0:\n",
    "                header = \",\".join(str(ele) for ele in range(vector_size))\n",
    "                word2vec_file.write(header)\n",
    "                word2vec_file.write(\"\\n\")\n",
    "            # Check if the line exists else it is vector of zeros\n",
    "            if type(v_norm) is list:  \n",
    "                line1 = \",\".join( [str(vector_element) for vector_element in v_norm] )\n",
    "            else:\n",
    "                line1 = \",\".join([str(0) for i in range(vector_size)])\n",
    "            word2vec_file.write(line1)\n",
    "            word2vec_file.write('\\n')\n",
    "            \n",
    "def save_word2vec_to_csv_y(Y_set, sentiment_col, word2vec_filename):\n",
    "    with open(word2vec_filename, 'w+') as word2vec_file:\n",
    "        for index, row in Y_set.iterrows():\n",
    "            if index == 0:\n",
    "                header = \"review_score\"\n",
    "                word2vec_file.write(header)\n",
    "                word2vec_file.write(\"\\n\")\n",
    "            word2vec_file.write(str(row[sentiment_col]))\n",
    "            word2vec_file.write('\\n')\n",
    "\n",
    "train_Y_word2vec_filename = OUTPUT_FOLDER +  f\"train_Y_{file_name_code}.csv\"\n",
    "test_Y_word2vec_filename = OUTPUT_FOLDER + f\"test_Y_{file_name_code}.csv\"\n",
    "\n",
    "save_word2vec_to_csv_y(Y_train, 'review_score', train_Y_word2vec_filename)\n",
    "save_word2vec_to_csv_y(Y_test, 'review_score', test_Y_word2vec_filename)\n",
    "\n",
    "# train_X_word2vec_filename = OUTPUT_FOLDER +  f\"train_X_{file_name_code}.csv\"\n",
    "# test_X_word2vec_filename = OUTPUT_FOLDER + f\"test_X_{file_name_code}.csv\"\n",
    "# \n",
    "# \n",
    "# save_word2vec_to_csv(X_train, w2v_model_wv, \"stemmed_text\", train_X_word2vec_filename)\n",
    "# save_word2vec_to_csv(X_test, w2v_model_wv, \"stemmed_text\", test_X_word2vec_filename)\n",
    "\n",
    "# save_word2vec_to_csv(X_train, w2v_model_cbow_wv, \"stemmed_text\", train_X_word2vec_cbow_filename)\n",
    "# save_word2vec_to_csv(X_test, w2v_model_cbow_wv, \"stemmed_text\", test_X_word2vec_cbow_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
